<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/.gitignore">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/.gitignore" />
              <option name="updatedContent" value="# Byte-compiled / optimized / DLL files&#10;__pycache__/&#10;*.py[cod]&#10;*.so&#10;*.egg&#10;*.egg-info/&#10;dist/&#10;build/&#10;*.manifest&#10;*.spec&#10;&#10;# Jupyter Notebook checkpoints&#10;.ipynb_checkpoints&#10;&#10;# Environment&#10;.env&#10;.venv&#10;env/&#10;venv/&#10;ENV/&#10;&#10;# VS Code settings&#10;.vscode/&#10;&#10;# MacOS&#10;.DS_Store&#10;&#10;# Windows&#10;Thumbs.db&#10;&#10;# Model and plot files&#10;face_recognition_model.h5&#10;plot.png&#10;&#10;# Images and results&#10;images/&#10;&#10;# Dataset&#10;/dataset/&#10;&#10;# Log and result files&#10;recognized_faces.txt&#10;attendance.csv&#10;&#10;# Others&#10;*.log&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/train_model.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/train_model.py" />
              <option name="originalContent" value="# train_model.py&#10;from tensorflow.keras.preprocessing.image import ImageDataGenerator&#10;from tensorflow.keras.optimizers import Adam&#10;from tensorflow.keras.preprocessing.image import img_to_array&#10;from tensorflow.keras.utils import to_categorical&#10;from sklearn.model_selection import train_test_split&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;import random&#10;import cv2&#10;import os&#10;import glob&#10;&#10;from model import build_model&#10;&#10;# Initial parameters&#10;epochs = 100&#10;lr = 1e-3&#10;batch_size = 64&#10;img_dims = (96, 96, 3)&#10;&#10;data = []&#10;labels = []&#10;&#10;# Load image data from dataset&#10;image_files = [f for f in glob.glob(r'dataset' + &quot;/**/*&quot;, recursive=True) if&#10;               not os.path.isdir(f) and f != 'dataset/labels.txt']&#10;random.shuffle(image_files)&#10;&#10;# Read labels from file&#10;with open('dataset/labels.txt', 'r') as file:&#10;    _labels = file.read().split('\n')&#10;&#10;for img in image_files:&#10;    image = cv2.imread(img)&#10;&#10;    # Check if image was not loaded successfully&#10;    if image is None:&#10;        print(f&quot;Error loading image: {img}&quot;)&#10;        continue&#10;&#10;    # If image is loaded successfully, resize it&#10;    image = cv2.resize(image, (img_dims[0], img_dims[1]))&#10;    image = img_to_array(image)&#10;    data.append(image)&#10;&#10;    label = img.split(os.path.sep)[-2]&#10;    label = _labels.index(label)&#10;    labels.append([label])&#10;&#10;data = np.array(data, dtype=&quot;float&quot;) / 255.0&#10;labels = np.array(labels)&#10;&#10;(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)&#10;trainY = to_categorical(trainY, num_classes=len(_labels))&#10;testY = to_categorical(testY, num_classes=len(_labels))&#10;&#10;aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2,&#10;                         zoom_range=0.2, horizontal_flip=True)&#10;&#10;model = build_model(width=img_dims[0], height=img_dims[1], depth=img_dims[2], classes=len(_labels))&#10;opt = Adam(learning_rate=lr, weight_decay=lr / epochs)&#10;model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;])&#10;&#10;# Train the model&#10;H = model.fit(&#10;    aug.flow(trainX, trainY, batch_size=batch_size),&#10;    validation_data=(testX, testY),&#10;    steps_per_epoch=len(trainX) // batch_size,&#10;    epochs=epochs,&#10;    verbose=1&#10;)&#10;model.save('face_recognition_model.h5')&#10;&#10;# Draw training loss and accuracy plot&#10;plt.style.use(&quot;ggplot&quot;)&#10;plt.figure()&#10;N = epochs&#10;plt.plot(np.arange(0, N), H.history[&quot;loss&quot;], label=&quot;Train Loss&quot;)&#10;plt.plot(np.arange(0, N), H.history[&quot;val_loss&quot;], label=&quot;Validation Loss&quot;)&#10;plt.plot(np.arange(0, N), H.history[&quot;accuracy&quot;], label=&quot;Train Accuracy&quot;)&#10;plt.plot(np.arange(0, N), H.history[&quot;val_accuracy&quot;], label=&quot;Validation Accuracy&quot;)&#10;plt.title(&quot;Loss and Accuracy During Training&quot;)&#10;plt.xlabel(&quot;Epoch #&quot;)&#10;plt.ylabel(&quot;Loss/Accuracy&quot;)&#10;plt.legend(loc=&quot;upper right&quot;)&#10;plt.savefig('plot.png')" />
              <option name="updatedContent" value="# train_model.py&#10;from tensorflow.keras.preprocessing.image import ImageDataGenerator&#10;from tensorflow.keras.optimizers import Adam&#10;from tensorflow.keras.preprocessing.image import img_to_array&#10;from tensorflow.keras.utils import to_categorical&#10;from sklearn.model_selection import train_test_split&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;import random&#10;import cv2&#10;import os&#10;import glob&#10;&#10;from model import build_model&#10;&#10;# Initial parameters&#10;epochs = 100&#10;lr = 1e-3&#10;batch_size = 64&#10;img_dims = (96, 96, 3)&#10;&#10;data = []&#10;labels = []&#10;&#10;# Load image data from dataset&#10;image_files = [f for f in glob.glob(r'dataset' + &quot;/**/*&quot;, recursive=True) if&#10;               not os.path.isdir(f) and f != 'dataset/labels.txt']&#10;random.shuffle(image_files)&#10;&#10;# Read labels from file&#10;with open('dataset/labels.txt', 'r') as file:&#10;    _labels = file.read().split('\n')&#10;&#10;for img in image_files:&#10;    image = cv2.imread(img)&#10;&#10;    # Check if image was not loaded successfully&#10;    if image is None:&#10;        print(f&quot;Error loading image: {img}&quot;)&#10;        continue&#10;&#10;    # If image is loaded successfully, resize it&#10;    image = cv2.resize(image, (img_dims[0], img_dims[1]))&#10;    image = img_to_array(image)&#10;    data.append(image)&#10;&#10;    label = img.split(os.path.sep)[-2]&#10;    label = _labels.index(label)&#10;    labels.append([label])&#10;&#10;# Convert data and labels to numpy arrays and normalize&#10;data = np.array(data, dtype=&quot;float32&quot;) / 255.0&#10;labels = np.array(labels)&#10;&#10;# Split data into training and testing sets&#10;trainX, testX, trainY, testY = train_test_split(&#10;    data, labels, test_size=0.2, random_state=42&#10;)&#10;trainY = to_categorical(trainY, num_classes=len(_labels))&#10;testY = to_categorical(testY, num_classes=len(_labels))&#10;&#10;# Data augmentation&#10;aug = ImageDataGenerator(&#10;    rotation_range=25,&#10;    width_shift_range=0.1,&#10;    height_shift_range=0.1,&#10;    shear_range=0.2,&#10;    zoom_range=0.2,&#10;    horizontal_flip=True&#10;)&#10;&#10;# Build and compile the model&#10;model = build_model(&#10;    width=img_dims[0],&#10;    height=img_dims[1],&#10;    depth=img_dims[2],&#10;    classes=len(_labels)&#10;)&#10;opt = Adam(learning_rate=lr, weight_decay=lr / epochs)&#10;model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;])&#10;&#10;# Train the model&#10;H = model.fit(&#10;    aug.flow(trainX, trainY, batch_size=batch_size),&#10;    validation_data=(testX, testY),&#10;    steps_per_epoch=len(trainX) // batch_size,&#10;    epochs=epochs,&#10;    verbose=1&#10;)&#10;model.save('face_recognition_model.h5')&#10;&#10;# Draw training loss and accuracy plot&#10;plt.style.use(&quot;ggplot&quot;)&#10;plt.figure()&#10;N = epochs&#10;plt.plot(np.arange(0, N), H.history[&quot;loss&quot;], label=&quot;Train Loss&quot;)&#10;plt.plot(np.arange(0, N), H.history[&quot;val_loss&quot;], label=&quot;Validation Loss&quot;)&#10;plt.plot(np.arange(0, N), H.history[&quot;accuracy&quot;], label=&quot;Train Accuracy&quot;)&#10;plt.plot(np.arange(0, N), H.history[&quot;val_accuracy&quot;], label=&quot;Validation Accuracy&quot;)&#10;plt.title(&quot;Loss and Accuracy During Training&quot;)&#10;plt.xlabel(&quot;Epoch #&quot;)&#10;plt.ylabel(&quot;Loss/Accuracy&quot;)&#10;plt.legend(loc=&quot;upper right&quot;)&#10;plt.savefig('plot.png')" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>